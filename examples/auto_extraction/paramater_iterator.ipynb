{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paramater Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on datasets\n",
    "printing all the names of datasets availeble in torchvision.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10\n",
      "CIFAR100\n",
      "CLEVRClassification\n",
      "CREStereo\n",
      "Caltech101\n",
      "Caltech256\n",
      "CarlaStereo\n",
      "CelebA\n",
      "Cityscapes\n",
      "CocoCaptions\n",
      "CocoDetection\n",
      "Country211\n",
      "DTD\n",
      "DatasetFolder\n",
      "EMNIST\n",
      "ETH3DStereo\n",
      "EuroSAT\n",
      "FER2013\n",
      "FGVCAircraft\n",
      "FakeData\n",
      "FallingThingsStereo\n",
      "FashionMNIST\n",
      "Flickr30k\n",
      "Flickr8k\n",
      "Flowers102\n",
      "FlyingChairs\n",
      "FlyingThings3D\n",
      "Food101\n",
      "GTSRB\n",
      "HD1K\n",
      "HMDB51\n",
      "INaturalist\n",
      "ImageFolder\n",
      "ImageNet\n",
      "InStereo2k\n",
      "KMNIST\n",
      "Kinetics\n",
      "Kitti\n",
      "Kitti2012Stereo\n",
      "Kitti2015Stereo\n",
      "KittiFlow\n",
      "LFWPairs\n",
      "LFWPeople\n",
      "LSUN\n",
      "LSUNClass\n",
      "MNIST\n",
      "Middlebury2014Stereo\n",
      "MovingMNIST\n",
      "Omniglot\n",
      "OxfordIIITPet\n",
      "PCAM\n",
      "PhotoTour\n",
      "Places365\n",
      "QMNIST\n",
      "RenderedSST2\n",
      "SBDataset\n",
      "SBU\n",
      "SEMEION\n",
      "STL10\n",
      "SUN397\n",
      "SVHN\n",
      "SceneFlowStereo\n",
      "Sintel\n",
      "SintelStereo\n",
      "StanfordCars\n",
      "UCF101\n",
      "USPS\n",
      "VOCDetection\n",
      "VOCSegmentation\n",
      "VisionDataset\n",
      "WIDERFace\n",
      "__all__\n",
      "__builtins__\n",
      "__cached__\n",
      "__doc__\n",
      "__file__\n",
      "__getattr__\n",
      "__loader__\n",
      "__name__\n",
      "__package__\n",
      "__path__\n",
      "__spec__\n",
      "_optical_flow\n",
      "_stereo_matching\n",
      "caltech\n",
      "celeba\n",
      "cifar\n",
      "cityscapes\n",
      "clevr\n",
      "coco\n",
      "country211\n",
      "dtd\n",
      "eurosat\n",
      "fakedata\n",
      "fer2013\n",
      "fgvc_aircraft\n",
      "flickr\n",
      "flowers102\n",
      "folder\n",
      "food101\n",
      "gtsrb\n",
      "hmdb51\n",
      "imagenet\n",
      "inaturalist\n",
      "kinetics\n",
      "kitti\n",
      "lfw\n",
      "lsun\n",
      "mnist\n",
      "moving_mnist\n",
      "omniglot\n",
      "oxford_iiit_pet\n",
      "pcam\n",
      "phototour\n",
      "places365\n",
      "rendered_sst2\n",
      "sbd\n",
      "sbu\n",
      "semeion\n",
      "stanford_cars\n",
      "stl10\n",
      "sun397\n",
      "svhn\n",
      "ucf101\n",
      "usps\n",
      "utils\n",
      "video_utils\n",
      "vision\n",
      "voc\n",
      "widerface\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as TVD\n",
    "itt=dir(TVD)\n",
    "for i in itt:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveAvgPool1d\n",
      "AdaptiveAvgPool2d\n",
      "AdaptiveAvgPool3d\n",
      "AdaptiveLogSoftmaxWithLoss\n",
      "AdaptiveMaxPool1d\n",
      "AdaptiveMaxPool2d\n",
      "AdaptiveMaxPool3d\n",
      "AlphaDropout\n",
      "AvgPool1d\n",
      "AvgPool2d\n",
      "AvgPool3d\n",
      "BCELoss\n",
      "BCEWithLogitsLoss\n",
      "BatchNorm1d\n",
      "BatchNorm2d\n",
      "BatchNorm3d\n",
      "Bilinear\n",
      "CELU\n",
      "CTCLoss\n",
      "ChannelShuffle\n",
      "CircularPad1d\n",
      "CircularPad2d\n",
      "CircularPad3d\n",
      "ConstantPad1d\n",
      "ConstantPad2d\n",
      "ConstantPad3d\n",
      "Container\n",
      "Conv1d\n",
      "Conv2d\n",
      "Conv3d\n",
      "ConvTranspose1d\n",
      "ConvTranspose2d\n",
      "ConvTranspose3d\n",
      "CosineEmbeddingLoss\n",
      "CosineSimilarity\n",
      "CrossEntropyLoss\n",
      "CrossMapLRN2d\n",
      "DataParallel\n",
      "Dropout\n",
      "Dropout1d\n",
      "Dropout2d\n",
      "Dropout3d\n",
      "ELU\n",
      "Embedding\n",
      "EmbeddingBag\n",
      "FeatureAlphaDropout\n",
      "Flatten\n",
      "Fold\n",
      "FractionalMaxPool2d\n",
      "FractionalMaxPool3d\n",
      "GELU\n",
      "GLU\n",
      "GRU\n",
      "GRUCell\n",
      "GaussianNLLLoss\n",
      "GroupNorm\n",
      "Hardshrink\n",
      "Hardsigmoid\n",
      "Hardswish\n",
      "Hardtanh\n",
      "HingeEmbeddingLoss\n",
      "HuberLoss\n",
      "Identity\n",
      "InstanceNorm1d\n",
      "InstanceNorm2d\n",
      "InstanceNorm3d\n",
      "KLDivLoss\n",
      "L1Loss\n",
      "LPPool1d\n",
      "LPPool2d\n",
      "LSTM\n",
      "LSTMCell\n",
      "LayerNorm\n",
      "LazyBatchNorm1d\n",
      "LazyBatchNorm2d\n",
      "LazyBatchNorm3d\n",
      "LazyConv1d\n",
      "LazyConv2d\n",
      "LazyConv3d\n",
      "LazyConvTranspose1d\n",
      "LazyConvTranspose2d\n",
      "LazyConvTranspose3d\n",
      "LazyInstanceNorm1d\n",
      "LazyInstanceNorm2d\n",
      "LazyInstanceNorm3d\n",
      "LazyLinear\n",
      "LeakyReLU\n",
      "Linear\n",
      "LocalResponseNorm\n",
      "LogSigmoid\n",
      "LogSoftmax\n",
      "MSELoss\n",
      "MarginRankingLoss\n",
      "MaxPool1d\n",
      "MaxPool2d\n",
      "MaxPool3d\n",
      "MaxUnpool1d\n",
      "MaxUnpool2d\n",
      "MaxUnpool3d\n",
      "Mish\n",
      "Module\n",
      "ModuleDict\n",
      "ModuleList\n",
      "MultiLabelMarginLoss\n",
      "MultiLabelSoftMarginLoss\n",
      "MultiMarginLoss\n",
      "MultiheadAttention\n",
      "NLLLoss\n",
      "NLLLoss2d\n",
      "PReLU\n",
      "PairwiseDistance\n",
      "Parameter\n",
      "ParameterDict\n",
      "ParameterList\n",
      "PixelShuffle\n",
      "PixelUnshuffle\n",
      "PoissonNLLLoss\n",
      "RNN\n",
      "RNNBase\n",
      "RNNCell\n",
      "RNNCellBase\n",
      "RReLU\n",
      "ReLU\n",
      "ReLU6\n",
      "ReflectionPad1d\n",
      "ReflectionPad2d\n",
      "ReflectionPad3d\n",
      "ReplicationPad1d\n",
      "ReplicationPad2d\n",
      "ReplicationPad3d\n",
      "SELU\n",
      "Sequential\n",
      "SiLU\n",
      "Sigmoid\n",
      "SmoothL1Loss\n",
      "SoftMarginLoss\n",
      "Softmax\n",
      "Softmax2d\n",
      "Softmin\n",
      "Softplus\n",
      "Softshrink\n",
      "Softsign\n",
      "SyncBatchNorm\n",
      "Tanh\n",
      "Tanhshrink\n",
      "Threshold\n",
      "Transformer\n",
      "TransformerDecoder\n",
      "TransformerDecoderLayer\n",
      "TransformerEncoder\n",
      "TransformerEncoderLayer\n",
      "TripletMarginLoss\n",
      "TripletMarginWithDistanceLoss\n",
      "Unflatten\n",
      "Unfold\n",
      "UninitializedBuffer\n",
      "UninitializedParameter\n",
      "Upsample\n",
      "UpsamplingBilinear2d\n",
      "UpsamplingNearest2d\n",
      "ZeroPad1d\n",
      "ZeroPad2d\n",
      "ZeroPad3d\n",
      "__builtins__\n",
      "__cached__\n",
      "__doc__\n",
      "__file__\n",
      "__loader__\n",
      "__name__\n",
      "__package__\n",
      "__path__\n",
      "__spec__\n",
      "_reduction\n",
      "common_types\n",
      "factory_kwargs\n",
      "functional\n",
      "grad\n",
      "init\n",
      "intrinsic\n",
      "modules\n",
      "parallel\n",
      "parameter\n",
      "qat\n",
      "quantizable\n",
      "quantized\n",
      "utils\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as neuralLayers\n",
    "itt=dir(neuralLayers)\n",
    "for i in itt:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_destination\n",
      "__annotations__\n",
      "__call__\n",
      "__class__\n",
      "__constants__\n",
      "__delattr__\n",
      "__dict__\n",
      "__dir__\n",
      "__doc__\n",
      "__eq__\n",
      "__format__\n",
      "__ge__\n",
      "__getattr__\n",
      "__getattribute__\n",
      "__getstate__\n",
      "__gt__\n",
      "__hash__\n",
      "__init__\n",
      "__init_subclass__\n",
      "__le__\n",
      "__lt__\n",
      "__module__\n",
      "__ne__\n",
      "__new__\n",
      "__reduce__\n",
      "__reduce_ex__\n",
      "__repr__\n",
      "__setattr__\n",
      "__setstate__\n",
      "__sizeof__\n",
      "__str__\n",
      "__subclasshook__\n",
      "__weakref__\n",
      "_apply\n",
      "_call_impl\n",
      "_compiled_call_impl\n",
      "_conv_forward\n",
      "_get_backward_hooks\n",
      "_get_backward_pre_hooks\n",
      "_get_name\n",
      "_load_from_state_dict\n",
      "_maybe_warn_non_full_backward_hook\n",
      "_named_members\n",
      "_register_load_state_dict_pre_hook\n",
      "_register_state_dict_hook\n",
      "_replicate_for_data_parallel\n",
      "_save_to_state_dict\n",
      "_slow_forward\n",
      "_version\n",
      "_wrapped_call_impl\n",
      "add_module\n",
      "apply\n",
      "bfloat16\n",
      "buffers\n",
      "call_super_init\n",
      "children\n",
      "compile\n",
      "cpu\n",
      "cuda\n",
      "double\n",
      "dump_patches\n",
      "eval\n",
      "extra_repr\n",
      "float\n",
      "forward\n",
      "get_buffer\n",
      "get_extra_state\n",
      "get_parameter\n",
      "get_submodule\n",
      "half\n",
      "ipu\n",
      "load_state_dict\n",
      "modules\n",
      "named_buffers\n",
      "named_children\n",
      "named_modules\n",
      "named_parameters\n",
      "parameters\n",
      "register_backward_hook\n",
      "register_buffer\n",
      "register_forward_hook\n",
      "register_forward_pre_hook\n",
      "register_full_backward_hook\n",
      "register_full_backward_pre_hook\n",
      "register_load_state_dict_post_hook\n",
      "register_module\n",
      "register_parameter\n",
      "register_state_dict_pre_hook\n",
      "requires_grad_\n",
      "reset_parameters\n",
      "set_extra_state\n",
      "share_memory\n",
      "state_dict\n",
      "to\n",
      "to_empty\n",
      "train\n",
      "type\n",
      "xpu\n",
      "zero_grad\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "itt=dir(nn.Conv1d)\n",
    "for i in itt:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some test for the inspector library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies a 1D convolution over an input signal composed of several input\n",
      "planes.\n",
      "\n",
      "In the simplest case, the output value of the layer with input size\n",
      ":math:`(N, C_{\\text{in}}, L)` and output :math:`(N, C_{\\text{out}}, L_{\\text{out}})` can be\n",
      "precisely described as:\n",
      "\n",
      ".. math::\n",
      "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
      "    \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n",
      "    \\star \\text{input}(N_i, k)\n",
      "\n",
      "where :math:`\\star` is the valid `cross-correlation`_ operator,\n",
      ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
      ":math:`L` is a length of signal sequence.\n",
      "\n",
      "\n",
      "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "\n",
      "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      "\n",
      "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
      "  number or a one-element tuple.\n",
      "\n",
      "* :attr:`padding` controls the amount of padding applied to the input. It\n",
      "  can be either a string {'valid', 'same'} or a tuple of ints giving the\n",
      "  amount of implicit padding applied on both sides.\n",
      "\n",
      "* :attr:`dilation` controls the spacing between the kernel points; also\n",
      "  known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
      "  has a nice visualization of what :attr:`dilation` does.\n",
      "\n",
      "* :attr:`groups` controls the connections between inputs and outputs.\n",
      "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
      "  :attr:`groups`. For example,\n",
      "\n",
      "    * At groups=1, all inputs are convolved to all outputs.\n",
      "    * At groups=2, the operation becomes equivalent to having two conv\n",
      "      layers side by side, each seeing half the input channels\n",
      "      and producing half the output channels, and both subsequently\n",
      "      concatenated.\n",
      "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
      "      its own set of filters (of size\n",
      "      :math:`\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}`).\n",
      "\n",
      "Note:\n",
      "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
      "    where `K` is a positive integer, this operation is also known as a \"depthwise convolution\".\n",
      "\n",
      "    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
      "    a depthwise convolution with a depthwise multiplier `K` can be performed with the arguments\n",
      "    :math:`(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})`.\n",
      "Note:\n",
      "    In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting ``torch.backends.cudnn.deterministic = True``. See :doc:`/notes/randomness` for more information.\n",
      "\n",
      "Note:\n",
      "    ``padding='valid'`` is the same as no padding. ``padding='same'`` pads\n",
      "    the input so the output has the shape as the input. However, this mode\n",
      "    doesn't support any stride values other than 1.\n",
      "\n",
      "Note:\n",
      "    This module supports complex data types i.e. ``complex32, complex64, complex128``.\n",
      "\n",
      "Args:\n",
      "    in_channels (int): Number of channels in the input image\n",
      "    out_channels (int): Number of channels produced by the convolution\n",
      "    kernel_size (int or tuple): Size of the convolving kernel\n",
      "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      "    padding (int, tuple or str, optional): Padding added to both sides of\n",
      "        the input. Default: 0\n",
      "    padding_mode (str, optional): ``'zeros'``, ``'reflect'``,\n",
      "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
      "    dilation (int or tuple, optional): Spacing between kernel\n",
      "        elements. Default: 1\n",
      "    groups (int, optional): Number of blocked connections from input\n",
      "        channels to output channels. Default: 1\n",
      "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
      "        output. Default: ``True``\n",
      "\n",
      "\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(N, C_{in}, L_{in})` or :math:`(C_{in}, L_{in})`\n",
      "    - Output: :math:`(N, C_{out}, L_{out})` or :math:`(C_{out}, L_{out})`, where\n",
      "\n",
      "      .. math::\n",
      "          L_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n",
      "                    \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n",
      "\n",
      "Attributes:\n",
      "    weight (Tensor): the learnable weights of the module of shape\n",
      "        :math:`(\\text{out\\_channels},\n",
      "        \\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})`.\n",
      "        The values of these weights are sampled from\n",
      "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
      "    bias (Tensor):   the learnable bias of the module of shape\n",
      "        (out_channels). If :attr:`bias` is ``True``, then the values of these weights are\n",
      "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> m = nn.Conv1d(16, 33, 3, stride=2)\n",
      "    >>> input = torch.randn(20, 16, 50)\n",
      "    >>> output = m(input)\n",
      "\n",
      ".. _cross-correlation:\n",
      "    https://en.wikipedia.org/wiki/Cross-correlation\n",
      "\n",
      ".. _link:\n",
      "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "print(inspect.cleandoc(inspect.getdoc(nn.Conv1d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels\n",
      "<class 'int'>\n",
      "out_channels\n",
      "<class 'int'>\n",
      "groups\n",
      "<class 'int'>\n",
      "padding_mode\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "annotationslist=[type(1),type('a')]\n",
    "\n",
    "inspector =inspect.signature(nn.Conv1d).parameters\n",
    "for i in inspector:\n",
    "    if(\n",
    "        (inspector[i].kind==inspect._ParameterKind.POSITIONAL_OR_KEYWORD) \n",
    "        and\n",
    "        (inspector[i].annotation in annotationslist )\n",
    "        ):\n",
    "        print(inspector[i].name)\n",
    "        # print(inspector[i].default)\n",
    "        print(inspector[i].annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
